import json
import random
import asyncio
import shutil
import os
import sys
import itertools
import time
from hashlib import sha256

from src.util.util import Peer, decode_peers
from src.messages.body import ErrorCode, ACHNK_body
from src.messages.body import MsgType, GCHNK_body, REPRT_body, APEER_body
from src.messages.pack import pack, unpack
from src.peer.peer_server import run_peer_server

global IP_ADDR

CHUNK_SIZE = 1024

MAX_DOWNLOAD_CONNECTIONS = 2
CHUNK_UNAVAILABLE_RETRY_SECONDS = 5
DOWNLOAD_REPORTING_INTERVAL_SECONDS = 3
CLIENT_COMM_SOCKET_PATH = '/tmp/peer_server.sock'
COORDINATOR_CONN_RETRY_SECONDS = 10
COORDINATOR_ADDR = '10.5.0.10'
COORDINATOR_PORT = 8000
RESOURCE_DIR = 'resources'


async def _query_coordinator_for_file_peers(
        file_hash: str
) -> list[Peer]:
    """
    Query coordinator for list of peers which have the given file
    """
    writer = None
    while not writer:
        try:
            reader, writer = await asyncio.open_connection(COORDINATOR_ADDR, COORDINATOR_PORT)
        except OSError as e:
            print(f"Coordinator not available ({repr(e)}), retrying in {COORDINATOR_CONN_RETRY_SECONDS} seconds")
    try:
        apeer_msg = pack(APEER_body(msg_type=MsgType.APEER.value, file_hash=str.encode(file_hash)))
        writer.write(apeer_msg)
        await writer.drain()
        msg_type = await reader.readexactly(n=1)
    finally:
        writer.close()

    # check mgs type
    if int.from_bytes(msg_type, byteorder='little', signed=False) == MsgType.ERROR.value:
        body = await reader.readexactly(n=3)
        error_msg = unpack(msg_type + body, msg_type=MsgType.ERROR)
        if error_msg.error_code == ErrorCode.NO_FILE_FOUND.value:
            raise ValueError("File not found")
        else:
            raise ValueError("Error downloading file")
    # unpack the message
    prefix = msg_type + await reader.readexactly(n=43)
    num_peers = int.from_bytes(prefix[-4:], byteorder='little', signed=False)
    peers_bytes = await reader.readexactly(n=num_peers * 8)
    peers_response = unpack(prefix + peers_bytes, MsgType.PEERS)
    return [
        peer for peer in decode_peers(peers_response.peers)
        if peer.address != IP_ADDR]


async def _download_chunk(
        reader: asyncio.StreamReader,
        writer: asyncio.StreamWriter,
        file_hash: str,
        chunk_num: int
) -> bytes:
    """
    Download a given chunk using provided reader and writer and return it
    """
    file_hash_bytes = str.encode(file_hash)
    gchnk_bytes = pack(GCHNK_body(msg_type=MsgType.GCHNK.value, file_hash=file_hash_bytes,
                                  chunk_num=chunk_num))

    writer.write(gchnk_bytes)
    await writer.drain()
    prefix = await reader.readexactly(n=72 + CHUNK_SIZE)
    unpacked = unpack(data=prefix, msg_type=MsgType.SCHNK)
    assert unpacked.msg_type == MsgType.SCHNK.value
    assert unpacked.chunk_num == chunk_num
    assert unpacked.file_hash == file_hash_bytes

    return unpacked.content


async def download_file(fileinfo: dict, out_name: str):
    """
    Download a file and save it under `out_name`. Use `fileinfo` generated by `create_fileinfo.py`.
    """

    partial_file = f"{out_name}.partial"

    size = fileinfo['file_size']
    file_hash = fileinfo['file_hash']
    chunk_hashes = fileinfo['chunk_hashes']
    num_chunks = fileinfo['num_chunks']

    retry_queue = asyncio.Queue()

    sem = asyncio.Semaphore(MAX_DOWNLOAD_CONNECTIONS)

    chunk_peers_mapping = {}

    got_chunks = False

    async def _report_availability(avail_type: int):
        """
        Send a REPRT message to coordinator
        """
        assert avail_type in (0, 1, 2)

        writer = None
        while not writer:
            try:
                reader, writer = await asyncio.open_connection(COORDINATOR_ADDR, COORDINATOR_PORT)
            except OSError as e:
                print(f"Coordinator not available ({repr(e)}), retrying in {COORDINATOR_CONN_RETRY_SECONDS} seconds")
        try:
            reprt_msg = pack(REPRT_body(
                msg_type=MsgType.REPRT.value,
                file_hash=str.encode(file_hash),
                availability=avail_type,
                file_size=size))
            writer.write(reprt_msg)
            await writer.drain()
        finally:
            writer.close()

    async def _report_partial_availability_task():
        """
        Periodically report partial availability if some chunks have been downloaded. Cancel this task before returning.
        """
        while True:
            if got_chunks:
                print("Reporting partial availability")
                await _report_availability(1)
            else:
                print("No chunks downloaded, skipping report")

            await asyncio.sleep(DOWNLOAD_REPORTING_INTERVAL_SECONDS)

    async def build_chunk_peer_mapping() -> dict[int, list[str]]:
        """
        Query the coordinator for a given file, query peers with partial availability
         and map chunk numbers to peers which own them. Note that the mapping will not contain
         chunks which are not owned by any peer.
        """
        try:
            peers = await _query_coordinator_for_file_peers(file_hash)

            all_chunks_addrs = [peer.address for peer in peers if peer.availability == 2]
            partial_addrs = [peer.address for peer in peers if peer.availability == 1]

            # put all peers with full availability in mapping
            mapping = {
                i: all_chunks_addrs.copy() for i in range(num_chunks)
            }

            async def query_peer_for_partial_availability(addr: str) -> list[int]:
                """
                Send ACHNK to peer and get the list of available chunks from file.
                """
                reader, writer = await asyncio.open_connection(addr, 8000)
                try:
                    achnk_msg = pack(ACHNK_body(msg_type=MsgType.ACHNK.value, file_hash=str.encode(file_hash)))
                    writer.write(achnk_msg)
                    await writer.drain()
                    msg_type = await reader.readexactly(n=1)
                    if int.from_bytes(msg_type, byteorder='little', signed=False) == MsgType.ERROR.value:
                        body = await reader.readexactly(n=3)
                        error_msg = unpack(msg_type + body, msg_type=MsgType.ERROR)
                        print(error_msg)
                        return list()
                    prefix = msg_type + await reader.readexactly(n=39)
                    num_chunks = int.from_bytes(prefix[-4:-2], byteorder='little', signed=False)
                    chunks_bytes = await reader.readexactly(n=num_chunks * 4)
                    chunks_response = unpack(prefix + chunks_bytes, MsgType.CHNKS)
                    avail_chunks = [
                        int.from_bytes(chunks_response.availability[i:i + 4], byteorder='little', signed=False)
                        for i in range(0, num_chunks * 4, 4)]
                    return avail_chunks
                finally:
                    writer.close()

            # Map peers with partial availability to chunks they own
            partial_avail_addr_to_num_mapping = zip(partial_addrs, await asyncio.gather(*[
                query_peer_for_partial_availability(addr) for addr in partial_addrs
            ]))

            # add to mapping
            for addr, avail_chunks in partial_avail_addr_to_num_mapping:
                for chunk_num in avail_chunks:
                    try:
                        mapping[chunk_num].append(addr)
                    except IndexError:
                        mapping[chunk_num] = [addr]

            return mapping
        except ValueError as e:
            print(repr(e))
            return dict()

    async def refresh_chunk_availability():
        """
        Update `chunk_peers_mapping`.
        """
        nonlocal chunk_peers_mapping
        chunk_peers_mapping = await build_chunk_peer_mapping()

    await refresh_chunk_availability()
    if not chunk_peers_mapping:
        print("File not available")
        return

    with open(partial_file, "wb") as fp:
        fp.truncate(size)

    # Put all unavailable chunks in retry queue
    for num in (num for num, addrs in chunk_peers_mapping.items() if len(addrs) == 0):
        await retry_queue.put((num, chunk_hashes[num]))

    def assign_chunks_to_peers(chunk_nums: list[int] = None) -> list[tuple[str, list[int]]]:
        """
        Randomly assign lists of chunks to peers. Put the rarest chunks at the start.
        """
        _chunk_addr_picks = [(num, random.choice(addrs)) for num, addrs in
                             sorted(chunk_peers_mapping.items(), key=lambda x: x[1]) if
                             len(addrs) > 0 and ((num in chunk_nums) if chunk_nums else True)]
        _num_peers_per_chunk = {num: len(addrs) for num, addrs in
                                sorted(chunk_peers_mapping.items(), key=lambda x: x[1]) if len(addrs) > 0}

        _addr_to_chunks_mapping = itertools.groupby(sorted(_chunk_addr_picks, key=lambda x: x[1]), key=lambda x: x[1])
        return [
            (addr, [_num for _num, _addr in list(sorted(grouped_list, key=lambda x: _num_peers_per_chunk[x[0]]))]) for
            addr, grouped_list in _addr_to_chunks_mapping]

    addr_chunks_pairs = assign_chunks_to_peers()

    async def _download_and_save_chunk(
            chunk_num: int,
            chunk_hash: str,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter
    ):
        """
        Download the given chunk and save it to `.partial` file
        """
        try:
            res = await _download_chunk(reader, writer, file_hash, chunk_num)
            if sha256(res).hexdigest()[:32] != chunk_hash:
                raise ValueError(f"Chunk {chunk_num} hash not matching")
            with open(partial_file, mode='r+b') as fp:
                fp.seek(chunk_num * CHUNK_SIZE)
                fp.write(res)
            nonlocal got_chunks
            got_chunks = True
        except Exception as e:
            print(f"{e} on chunk {chunk_num}")
            await retry_queue.put((chunk_num, chunk_hash))

    async def connect_and_save_chunks(
            host: str,
            port: int,
            chunk_nums: list[int],
            chunk_hashes: list[str]):
        """
        Connect to peer and download & save chunks sequentially
        """
        print(f"Connect to {host}:{port} and download {chunk_nums}")
        async with sem:
            reader, writer = await asyncio.open_connection(host, port)
            try:
                for coro in [_download_and_save_chunk(chunk_num, chunk_hash, reader, writer) for chunk_num, chunk_hash
                             in
                             zip(chunk_nums, chunk_hashes)]:
                    await coro
            finally:
                writer.close()

    partial_availability_reporting_task = asyncio.create_task(_report_partial_availability_task())

    try:
        # Download and save all instantly available chunks
        await asyncio.gather(
            *[connect_and_save_chunks(addr, 8000, chunk_num_list, [chunk_hashes[n] for n in chunk_num_list]) for
              addr, chunk_num_list, in addr_chunks_pairs])

        while not retry_queue.empty():
            # refresh availability
            await refresh_chunk_availability()

            items = []
            while not retry_queue.empty():
                items.append(await retry_queue.get())

            # find available and unavailable chunks
            available_items = [(chunk_num, chunk_hash) for chunk_num, chunk_hash in items if
                               chunk_peers_mapping.get(chunk_num)]
            unavailable_items = [(chunk_num, chunk_hash) for chunk_num, chunk_hash in items if not
            chunk_peers_mapping.get(chunk_num)]

            addr_chunks_pairs = assign_chunks_to_peers([num for num, _ in available_items])

            # download previously unavailable chunks
            await asyncio.gather(
                *[connect_and_save_chunks(addr, 8000, chunk_num_list, [chunk_hashes[n] for n in chunk_num_list]) for
                  addr, chunk_num_list, in addr_chunks_pairs])

            # put chunks which are still unavailable back in queue
            if unavailable_items:
                for item in unavailable_items:
                    await retry_queue.put(item)

                print(
                    f"Chunks {[num for num, _ in unavailable_items]} not available, retrying in {CHUNK_UNAVAILABLE_RETRY_SECONDS}s")
                await asyncio.sleep(CHUNK_UNAVAILABLE_RETRY_SECONDS)

        # remove null padding from file
        with open(partial_file, mode='rb') as fsource:
            with open(out_name, mode='wb') as fdest:
                shutil.copyfileobj(fsource, fdest)
                fdest.seek(-(CHUNK_SIZE - (size % CHUNK_SIZE)), os.SEEK_END)
                fdest.truncate()

        # check file hash
        with open(out_name, mode='rb') as fp:
            out_bytes = fp.read()

        if not sha256(out_bytes).hexdigest()[:32] == file_hash:
            print(f"File hash vs expected:\n{sha256(out_bytes).hexdigest()[:32]}\n{file_hash}")
            raise ValueError(f"File hash vs expected:\n{sha256(out_bytes).hexdigest()[:32]}\n{file_hash}")

        # report full availability
        await _report_availability(2)

        print(f"Hash is OK, wrote to {out_name}")
    finally:
        # cancel the availability reporting task
        if not partial_availability_reporting_task.cancelled():
            partial_availability_reporting_task.cancel()
        os.remove(partial_file)


def check_server_running() -> bool:
    """
    Ping the server socket, return True if got response
    """
    async def _ping_server():
        CLIENT_COMM_SOCKET_PATH = '/tmp/peer_server.sock'

        print("Ping server provess")
        reader, writer = await asyncio.open_unix_connection(CLIENT_COMM_SOCKET_PATH)
        writer.write(b'\x00')
        response = await reader.readexactly(1)
        assert response == b'\x00'

    try:
        asyncio.run(_ping_server())
        return True
    except FileNotFoundError:
        return False


def start_server(addr: str):
    """
    Run the reporting server in a separate process
    """
    pid = os.fork()
    if pid == 0:
        print("Started server")
        return

    with open("server.log", mode='w') as fp:
        fp.write("server running")

    SERVER_PORT = 8000
    REPORTING_INTERVAL_SECONDS = 15

    try:
        asyncio.run(run_peer_server(addr, SERVER_PORT, REPORTING_INTERVAL_SECONDS, CLIENT_COMM_SOCKET_PATH))
    except Exception as e:
        import traceback

        with open("server.log", mode='a') as fp:
            fp.write(traceback.format_exc())
    sys.exit(0)


def kill_server():
    """
    Send \x01 to reporting server, effectively killing it
    """
    async def _kill_server():
        CLIENT_COMM_SOCKET_PATH = '/tmp/peer_server.sock'

        print("Kill server process")
        reader, writer = await asyncio.open_unix_connection(CLIENT_COMM_SOCKET_PATH)
        writer.write(b'\x01')
        response = await reader.readexactly(1)
        assert response == b'\x01'
    try:
        try:
            asyncio.run(_kill_server())
            print("Killed server")
        except FileNotFoundError:
            print("Server not running")
    except Exception as e:
        print(f"Could not kill server: {repr(e)}")

def main():
    """
    Parse input and do stuff
    """
    if len(sys.argv) < 2:
        print_help()
        return
    try:
        command, params = sys.argv[1], sys.argv[2:]
    except IndexError:
        command = sys.argv[1]
        params = None
    match command:
        case "get":
            if len(params) != 2:
                print_help()
                return

            fileinfo_file, out_file = params
            print(f"Download file from {fileinfo_file}")
            if not check_server_running():
                start_server(IP_ADDR)

            asyncio.run(get_file(fileinfo_file, out_file))
        case "start-server":
            start_server(IP_ADDR)
        case "kill-server":
            kill_server()
        case _:
            print_help()


def print_help():
    help_str = """
    Download files from "torrent" network.
    
    Usage:
        python3 peer.py get <.fileinfo file> <out file>
        python3 peer.py start-server
        python3 peer.py kill-server
        python3 peer.py help
    """

    print(help_str)

async def get_file(fileinfo_file: str, out_file: str):
    """
    Download file from .fileinfo and save under given name in resource dir
    """
    try:
        with open(fileinfo_file, mode='r') as fp:
            fileinfo = json.load(fp)
            out_path =f'{RESOURCE_DIR}/{out_file}'
        await asyncio.gather(
            download_file(fileinfo, out_path)
        )

        print(f"Wrote to {out_path}")
    except Exception as e:
        print(repr(e))
        print("Failed downloading file")
        sys.exit(1)


if __name__ == '__main__':
    import socket

    global IP_ADDR

    hostname = socket.gethostname()
    IP_ADDR = socket.gethostbyname(hostname)

    main()
